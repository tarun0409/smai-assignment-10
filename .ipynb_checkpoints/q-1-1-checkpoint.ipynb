{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15:07</td>\n",
       "      <td>1169.41</td>\n",
       "      <td>1037784.0</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1187.5590</td>\n",
       "      <td>1159.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019/03/26</td>\n",
       "      <td>1184.62</td>\n",
       "      <td>1894639.0</td>\n",
       "      <td>1198.53</td>\n",
       "      <td>1202.8300</td>\n",
       "      <td>1176.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019/03/25</td>\n",
       "      <td>1193.00</td>\n",
       "      <td>1493841.0</td>\n",
       "      <td>1196.93</td>\n",
       "      <td>1206.3975</td>\n",
       "      <td>1187.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/03/22</td>\n",
       "      <td>1205.50</td>\n",
       "      <td>1668910.0</td>\n",
       "      <td>1226.32</td>\n",
       "      <td>1230.0000</td>\n",
       "      <td>1202.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019/03/21</td>\n",
       "      <td>1231.54</td>\n",
       "      <td>1195899.0</td>\n",
       "      <td>1216.00</td>\n",
       "      <td>1231.7900</td>\n",
       "      <td>1213.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    close     volume     open       high       low\n",
       "0       15:07  1169.41  1037784.0  1185.50  1187.5590  1159.370\n",
       "1  2019/03/26  1184.62  1894639.0  1198.53  1202.8300  1176.720\n",
       "2  2019/03/25  1193.00  1493841.0  1196.93  1206.3975  1187.040\n",
       "3  2019/03/22  1205.50  1668910.0  1226.32  1230.0000  1202.825\n",
       "4  2019/03/21  1231.54  1195899.0  1216.00  1231.7900  1213.150"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('GoogleStocks.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15:07</td>\n",
       "      <td>1169.41</td>\n",
       "      <td>1037784.0</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1187.5590</td>\n",
       "      <td>1159.370</td>\n",
       "      <td>1173.46450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019/03/26</td>\n",
       "      <td>1184.62</td>\n",
       "      <td>1894639.0</td>\n",
       "      <td>1198.53</td>\n",
       "      <td>1202.8300</td>\n",
       "      <td>1176.720</td>\n",
       "      <td>1189.77500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019/03/25</td>\n",
       "      <td>1193.00</td>\n",
       "      <td>1493841.0</td>\n",
       "      <td>1196.93</td>\n",
       "      <td>1206.3975</td>\n",
       "      <td>1187.040</td>\n",
       "      <td>1196.71875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/03/22</td>\n",
       "      <td>1205.50</td>\n",
       "      <td>1668910.0</td>\n",
       "      <td>1226.32</td>\n",
       "      <td>1230.0000</td>\n",
       "      <td>1202.825</td>\n",
       "      <td>1216.41250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019/03/21</td>\n",
       "      <td>1231.54</td>\n",
       "      <td>1195899.0</td>\n",
       "      <td>1216.00</td>\n",
       "      <td>1231.7900</td>\n",
       "      <td>1213.150</td>\n",
       "      <td>1222.47000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    close     volume     open       high       low         avg\n",
       "0       15:07  1169.41  1037784.0  1185.50  1187.5590  1159.370  1173.46450\n",
       "1  2019/03/26  1184.62  1894639.0  1198.53  1202.8300  1176.720  1189.77500\n",
       "2  2019/03/25  1193.00  1493841.0  1196.93  1206.3975  1187.040  1196.71875\n",
       "3  2019/03/22  1205.50  1668910.0  1226.32  1230.0000  1202.825  1216.41250\n",
       "4  2019/03/21  1231.54  1195899.0  1216.00  1231.7900  1213.150  1222.47000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_arr = data['low'].values\n",
    "high_arr = data['high'].values\n",
    "avg_arr = (low_arr + high_arr)/2\n",
    "data['avg'] = avg_arr\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2027218.0</td>\n",
       "      <td>979.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2593808.0</td>\n",
       "      <td>1032.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1829295.0</td>\n",
       "      <td>1068.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2258695.0</td>\n",
       "      <td>824.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1596058.0</td>\n",
       "      <td>925.9600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        volume        avg\n",
       "354  2027218.0   979.9000\n",
       "252  2593808.0  1032.0150\n",
       "97   1829295.0  1068.7925\n",
       "522  2258695.0   824.3700\n",
       "466  1596058.0   925.9600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test, out_train, out_test = train_test_split(\n",
    "    data[['volume','avg']],\n",
    "    data[['open']],\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_train_arr = out_train[['open']].values\n",
    "out_test_arr = out_test[['open']].values\n",
    "train_ts = data_train[['volume','avg']].values\n",
    "test_ts = data_test[['volume','avg']].values\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "sc.fit(train_ts)\n",
    "train_ts_scaled = sc.transform(train_ts)\n",
    "test_ts_scaled = sc.transform(test_ts)\n",
    "scy = MinMaxScaler(feature_range=(0,1))\n",
    "scy.fit(out_train_arr)\n",
    "out_train_scaled = scy.transform(out_train_arr)\n",
    "out_test_scaled = scy.transform(out_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "::::::::::::MODEL 1 ::::::::::::::::\n",
      "Number of Hidden Layers : 2\n",
      "Number of cells in Hidden Layers : 30\n",
      "Number of Time Steps : 20\n",
      "Number of Epochs : 100\n",
      "\n",
      "Epoch 1/100\n",
      "584/584 [==============================] - 0s 693us/step - loss: 0.1141\n",
      "Epoch 2/100\n",
      "584/584 [==============================] - 0s 231us/step - loss: 0.0736\n",
      "Epoch 3/100\n",
      "584/584 [==============================] - 0s 264us/step - loss: 0.0728\n",
      "Epoch 4/100\n",
      "584/584 [==============================] - 0s 212us/step - loss: 0.0737\n",
      "Epoch 5/100\n",
      "584/584 [==============================] - 0s 179us/step - loss: 0.0827\n",
      "Epoch 6/100\n",
      "584/584 [==============================] - 0s 191us/step - loss: 0.0708\n",
      "Epoch 7/100\n",
      "584/584 [==============================] - 0s 181us/step - loss: 0.0776\n",
      "Epoch 8/100\n",
      "584/584 [==============================] - 0s 203us/step - loss: 0.0724\n",
      "Epoch 9/100\n",
      "584/584 [==============================] - 0s 191us/step - loss: 0.0710\n",
      "Epoch 10/100\n",
      "584/584 [==============================] - 0s 195us/step - loss: 0.0856\n",
      "Epoch 11/100\n",
      "584/584 [==============================] - 0s 185us/step - loss: 0.0732\n",
      "Epoch 12/100\n",
      "584/584 [==============================] - 0s 237us/step - loss: 0.0750\n",
      "Epoch 13/100\n",
      "584/584 [==============================] - 0s 192us/step - loss: 0.0736\n",
      "Epoch 14/100\n",
      "584/584 [==============================] - 0s 206us/step - loss: 0.0965\n",
      "Epoch 15/100\n",
      "584/584 [==============================] - 0s 191us/step - loss: 0.0819\n",
      "Epoch 16/100\n",
      "584/584 [==============================] - 0s 198us/step - loss: 0.0693\n",
      "Epoch 17/100\n",
      "584/584 [==============================] - 0s 228us/step - loss: 0.0674\n",
      "Epoch 18/100\n",
      "584/584 [==============================] - 0s 279us/step - loss: 0.0709\n",
      "Epoch 19/100\n",
      "584/584 [==============================] - 0s 237us/step - loss: 0.0711\n",
      "Epoch 20/100\n",
      "584/584 [==============================] - 0s 370us/step - loss: 0.0684\n",
      "Epoch 21/100\n",
      "584/584 [==============================] - 0s 199us/step - loss: 0.0671\n",
      "Epoch 22/100\n",
      "584/584 [==============================] - 0s 187us/step - loss: 0.0842\n",
      "Epoch 23/100\n",
      "584/584 [==============================] - 0s 192us/step - loss: 0.0712\n",
      "Epoch 24/100\n",
      "584/584 [==============================] - 0s 189us/step - loss: 0.0670\n",
      "Epoch 25/100\n",
      "584/584 [==============================] - 0s 191us/step - loss: 0.0670\n",
      "Epoch 26/100\n",
      "584/584 [==============================] - 0s 186us/step - loss: 0.0696\n",
      "Epoch 27/100\n",
      "584/584 [==============================] - 0s 218us/step - loss: 0.0653\n",
      "Epoch 28/100\n",
      "584/584 [==============================] - 0s 203us/step - loss: 0.0652\n",
      "Epoch 29/100\n",
      "584/584 [==============================] - 0s 209us/step - loss: 0.0700\n",
      "Epoch 30/100\n",
      "584/584 [==============================] - 0s 215us/step - loss: 0.0659\n",
      "Epoch 31/100\n",
      "584/584 [==============================] - 0s 193us/step - loss: 0.0668\n",
      "Epoch 32/100\n",
      "584/584 [==============================] - 0s 198us/step - loss: 0.0656\n",
      "Epoch 33/100\n",
      "584/584 [==============================] - 0s 179us/step - loss: 0.0635\n",
      "Epoch 34/100\n",
      "584/584 [==============================] - 0s 189us/step - loss: 0.0633\n",
      "Epoch 35/100\n",
      "584/584 [==============================] - 0s 182us/step - loss: 0.0657\n",
      "Epoch 36/100\n",
      "584/584 [==============================] - 0s 230us/step - loss: 0.0647\n",
      "Epoch 37/100\n",
      "584/584 [==============================] - 0s 188us/step - loss: 0.0612\n",
      "Epoch 38/100\n",
      "584/584 [==============================] - 0s 185us/step - loss: 0.0656\n",
      "Epoch 39/100\n",
      "584/584 [==============================] - 0s 196us/step - loss: 0.0669\n",
      "Epoch 40/100\n",
      "584/584 [==============================] - 0s 183us/step - loss: 0.0618\n",
      "Epoch 41/100\n",
      "584/584 [==============================] - 0s 198us/step - loss: 0.0619\n",
      "Epoch 42/100\n",
      "584/584 [==============================] - 0s 185us/step - loss: 0.0611\n",
      "Epoch 43/100\n",
      "584/584 [==============================] - 0s 185us/step - loss: 0.0611\n",
      "Epoch 44/100\n",
      "584/584 [==============================] - 0s 187us/step - loss: 0.0624\n",
      "Epoch 45/100\n",
      "584/584 [==============================] - 0s 217us/step - loss: 0.0610\n",
      "Epoch 46/100\n",
      "584/584 [==============================] - 0s 188us/step - loss: 0.0590\n",
      "Epoch 47/100\n",
      "584/584 [==============================] - 0s 186us/step - loss: 0.0606\n",
      "Epoch 48/100\n",
      "584/584 [==============================] - 0s 187us/step - loss: 0.0632\n",
      "Epoch 49/100\n",
      "584/584 [==============================] - 0s 177us/step - loss: 0.0658\n",
      "Epoch 50/100\n",
      "584/584 [==============================] - 0s 204us/step - loss: 0.0564\n",
      "Epoch 51/100\n",
      "584/584 [==============================] - 0s 188us/step - loss: 0.0595\n",
      "Epoch 52/100\n",
      "584/584 [==============================] - 0s 183us/step - loss: 0.0570\n",
      "Epoch 53/100\n",
      "584/584 [==============================] - 0s 170us/step - loss: 0.0569\n",
      "Epoch 54/100\n",
      "584/584 [==============================] - 0s 216us/step - loss: 0.0575\n",
      "Epoch 55/100\n",
      "584/584 [==============================] - 0s 187us/step - loss: 0.0526\n",
      "Epoch 56/100\n",
      "584/584 [==============================] - 0s 173us/step - loss: 0.0580\n",
      "Epoch 57/100\n",
      "584/584 [==============================] - 0s 199us/step - loss: 0.0532\n",
      "Epoch 58/100\n",
      "584/584 [==============================] - 0s 191us/step - loss: 0.0518\n",
      "Epoch 59/100\n",
      "584/584 [==============================] - 0s 179us/step - loss: 0.0525\n",
      "Epoch 60/100\n",
      "584/584 [==============================] - 0s 184us/step - loss: 0.0518\n",
      "Epoch 61/100\n",
      "584/584 [==============================] - 0s 186us/step - loss: 0.0525\n",
      "Epoch 62/100\n",
      "584/584 [==============================] - 0s 247us/step - loss: 0.0540\n",
      "Epoch 63/100\n",
      "584/584 [==============================] - 0s 183us/step - loss: 0.0506\n",
      "Epoch 64/100\n",
      "584/584 [==============================] - 0s 184us/step - loss: 0.0529\n",
      "Epoch 65/100\n",
      "584/584 [==============================] - 0s 189us/step - loss: 0.0601\n",
      "Epoch 66/100\n",
      "584/584 [==============================] - 0s 182us/step - loss: 0.0501\n",
      "Epoch 67/100\n",
      "584/584 [==============================] - 0s 176us/step - loss: 0.0455\n",
      "Epoch 68/100\n",
      "584/584 [==============================] - 0s 180us/step - loss: 0.0449\n",
      "Epoch 69/100\n",
      "584/584 [==============================] - 0s 184us/step - loss: 0.0432\n",
      "Epoch 70/100\n",
      "584/584 [==============================] - 0s 190us/step - loss: 0.0469\n",
      "Epoch 71/100\n",
      "584/584 [==============================] - 0s 200us/step - loss: 0.0508\n",
      "Epoch 72/100\n",
      "584/584 [==============================] - 0s 185us/step - loss: 0.0453\n",
      "Epoch 73/100\n",
      "584/584 [==============================] - 0s 190us/step - loss: 0.0439\n",
      "Epoch 74/100\n",
      "584/584 [==============================] - 0s 180us/step - loss: 0.0399\n",
      "Epoch 75/100\n",
      "584/584 [==============================] - 0s 197us/step - loss: 0.0432\n",
      "Epoch 76/100\n",
      "584/584 [==============================] - 0s 183us/step - loss: 0.0475\n",
      "Epoch 77/100\n",
      "584/584 [==============================] - 0s 199us/step - loss: 0.0405\n",
      "Epoch 78/100\n",
      "584/584 [==============================] - 0s 224us/step - loss: 0.0367\n",
      "Epoch 79/100\n",
      "584/584 [==============================] - 0s 265us/step - loss: 0.0383\n",
      "Epoch 80/100\n",
      "584/584 [==============================] - 0s 272us/step - loss: 0.0388\n",
      "Epoch 81/100\n",
      "584/584 [==============================] - 0s 203us/step - loss: 0.0370\n",
      "Epoch 82/100\n",
      "584/584 [==============================] - 0s 185us/step - loss: 0.0358\n",
      "Epoch 83/100\n",
      "584/584 [==============================] - 0s 207us/step - loss: 0.0356\n",
      "Epoch 84/100\n",
      "584/584 [==============================] - 0s 177us/step - loss: 0.0341\n",
      "Epoch 85/100\n",
      "584/584 [==============================] - 0s 205us/step - loss: 0.0358\n",
      "Epoch 86/100\n",
      "584/584 [==============================] - 0s 193us/step - loss: 0.0333\n",
      "Epoch 87/100\n",
      "584/584 [==============================] - 0s 246us/step - loss: 0.0323\n",
      "Epoch 88/100\n",
      "584/584 [==============================] - 0s 270us/step - loss: 0.0357\n",
      "Epoch 89/100\n",
      "584/584 [==============================] - 0s 224us/step - loss: 0.0347\n",
      "Epoch 90/100\n",
      "584/584 [==============================] - 0s 174us/step - loss: 0.0300\n",
      "Epoch 91/100\n",
      "584/584 [==============================] - 0s 194us/step - loss: 0.0291\n",
      "Epoch 92/100\n",
      "584/584 [==============================] - 0s 189us/step - loss: 0.0295\n",
      "Epoch 93/100\n",
      "584/584 [==============================] - 0s 180us/step - loss: 0.0280\n",
      "Epoch 94/100\n",
      "584/584 [==============================] - 0s 180us/step - loss: 0.0259\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================] - 0s 182us/step - loss: 0.0275\n",
      "Epoch 96/100\n",
      "584/584 [==============================] - 0s 209us/step - loss: 0.0254\n",
      "Epoch 97/100\n",
      "584/584 [==============================] - 0s 179us/step - loss: 0.0244\n",
      "Epoch 98/100\n",
      "584/584 [==============================] - 0s 223us/step - loss: 0.0229\n",
      "Epoch 99/100\n",
      "584/584 [==============================] - 0s 183us/step - loss: 0.0249\n",
      "Epoch 100/100\n",
      "584/584 [==============================] - 0s 297us/step - loss: 0.0272\n",
      "132/132 [==============================] - 0s 504us/step\n",
      "\n",
      "Model 1 error : 0.11317653728253914\n",
      "\n",
      "=================================================================\n",
      "\n",
      "::::::::::::MODEL 2 ::::::::::::::::\n",
      "Number of Hidden Layers : 2\n",
      "Number of cells in Hidden Layers : 30\n",
      "Number of Time Steps : 50\n",
      "Number of Epochs : 50\n",
      "\n",
      "Epoch 1/50\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.1856\n",
      "Epoch 2/50\n",
      "554/554 [==============================] - 0s 470us/step - loss: 0.1053\n",
      "Epoch 3/50\n",
      "554/554 [==============================] - 0s 362us/step - loss: 0.0812\n",
      "Epoch 4/50\n",
      "554/554 [==============================] - 0s 359us/step - loss: 0.0764\n",
      "Epoch 5/50\n",
      "554/554 [==============================] - 0s 354us/step - loss: 0.0811\n",
      "Epoch 6/50\n",
      "554/554 [==============================] - 0s 359us/step - loss: 0.0837\n",
      "Epoch 7/50\n",
      "554/554 [==============================] - 0s 400us/step - loss: 0.0707\n",
      "Epoch 8/50\n",
      "554/554 [==============================] - 0s 365us/step - loss: 0.0770\n",
      "Epoch 9/50\n",
      "554/554 [==============================] - 0s 348us/step - loss: 0.0671\n",
      "Epoch 10/50\n",
      "554/554 [==============================] - 0s 356us/step - loss: 0.0648\n",
      "Epoch 11/50\n",
      "554/554 [==============================] - 0s 407us/step - loss: 0.0650\n",
      "Epoch 12/50\n",
      "554/554 [==============================] - 0s 453us/step - loss: 0.0710\n",
      "Epoch 13/50\n",
      "554/554 [==============================] - 0s 412us/step - loss: 0.0633\n",
      "Epoch 14/50\n",
      "554/554 [==============================] - 0s 381us/step - loss: 0.0677\n",
      "Epoch 15/50\n",
      "554/554 [==============================] - 0s 569us/step - loss: 0.0676\n",
      "Epoch 16/50\n",
      "554/554 [==============================] - 0s 712us/step - loss: 0.0619\n",
      "Epoch 17/50\n",
      "554/554 [==============================] - 0s 487us/step - loss: 0.0675\n",
      "Epoch 18/50\n",
      "554/554 [==============================] - 0s 392us/step - loss: 0.0776\n",
      "Epoch 19/50\n",
      "554/554 [==============================] - 0s 430us/step - loss: 0.0638\n",
      "Epoch 20/50\n",
      "554/554 [==============================] - 0s 406us/step - loss: 0.0622\n",
      "Epoch 21/50\n",
      "554/554 [==============================] - 0s 390us/step - loss: 0.0597\n",
      "Epoch 22/50\n",
      "554/554 [==============================] - 0s 408us/step - loss: 0.0603\n",
      "Epoch 23/50\n",
      "554/554 [==============================] - 0s 414us/step - loss: 0.0606\n",
      "Epoch 24/50\n",
      "554/554 [==============================] - 0s 382us/step - loss: 0.0671\n",
      "Epoch 25/50\n",
      "554/554 [==============================] - 0s 354us/step - loss: 0.0616\n",
      "Epoch 26/50\n",
      "554/554 [==============================] - 0s 404us/step - loss: 0.0634\n",
      "Epoch 27/50\n",
      "554/554 [==============================] - 0s 380us/step - loss: 0.0592\n",
      "Epoch 28/50\n",
      "554/554 [==============================] - 0s 457us/step - loss: 0.0568\n",
      "Epoch 29/50\n",
      "554/554 [==============================] - 0s 453us/step - loss: 0.0634\n",
      "Epoch 30/50\n",
      "554/554 [==============================] - 0s 447us/step - loss: 0.0583\n",
      "Epoch 31/50\n",
      "554/554 [==============================] - 0s 409us/step - loss: 0.0538\n",
      "Epoch 32/50\n",
      "554/554 [==============================] - 0s 415us/step - loss: 0.0526\n",
      "Epoch 33/50\n",
      "554/554 [==============================] - 0s 369us/step - loss: 0.0525\n",
      "Epoch 34/50\n",
      "554/554 [==============================] - 0s 375us/step - loss: 0.0629\n",
      "Epoch 35/50\n",
      "554/554 [==============================] - 0s 408us/step - loss: 0.0592\n",
      "Epoch 36/50\n",
      "554/554 [==============================] - 0s 444us/step - loss: 0.0552\n",
      "Epoch 37/50\n",
      "554/554 [==============================] - 0s 486us/step - loss: 0.0496\n",
      "Epoch 38/50\n",
      "554/554 [==============================] - 0s 460us/step - loss: 0.0510\n",
      "Epoch 39/50\n",
      "554/554 [==============================] - 0s 426us/step - loss: 0.0490\n",
      "Epoch 40/50\n",
      "554/554 [==============================] - 0s 446us/step - loss: 0.0548\n",
      "Epoch 41/50\n",
      "554/554 [==============================] - 0s 472us/step - loss: 0.0466\n",
      "Epoch 42/50\n",
      "554/554 [==============================] - 0s 421us/step - loss: 0.0469\n",
      "Epoch 43/50\n",
      "554/554 [==============================] - 0s 378us/step - loss: 0.0474\n",
      "Epoch 44/50\n",
      "554/554 [==============================] - 0s 394us/step - loss: 0.0480\n",
      "Epoch 45/50\n",
      "554/554 [==============================] - 0s 454us/step - loss: 0.0425\n",
      "Epoch 46/50\n",
      "554/554 [==============================] - 0s 377us/step - loss: 0.0457\n",
      "Epoch 47/50\n",
      "554/554 [==============================] - 0s 405us/step - loss: 0.0423\n",
      "Epoch 48/50\n",
      "554/554 [==============================] - 0s 436us/step - loss: 0.0368\n",
      "Epoch 49/50\n",
      "554/554 [==============================] - 0s 446us/step - loss: 0.0379\n",
      "Epoch 50/50\n",
      "554/554 [==============================] - 0s 409us/step - loss: 0.0361\n",
      "102/102 [==============================] - 0s 917us/step\n",
      "\n",
      "Model 2 error : 0.12040566054044985\n",
      "\n",
      "=================================================================\n",
      "\n",
      "::::::::::::MODEL 3 ::::::::::::::::\n",
      "Number of Hidden Layers : 2\n",
      "Number of cells in Hidden Layers : 30\n",
      "Number of Time Steps : 75\n",
      "Number of Epochs : 25\n",
      "\n",
      "Epoch 1/25\n",
      "529/529 [==============================] - 1s 1ms/step - loss: 0.2432\n",
      "Epoch 2/25\n",
      "529/529 [==============================] - 0s 715us/step - loss: 0.1138\n",
      "Epoch 3/25\n",
      "529/529 [==============================] - 0s 566us/step - loss: 0.0876\n",
      "Epoch 4/25\n",
      "529/529 [==============================] - 0s 526us/step - loss: 0.0752\n",
      "Epoch 5/25\n",
      "529/529 [==============================] - 0s 535us/step - loss: 0.0679\n",
      "Epoch 6/25\n",
      "529/529 [==============================] - 0s 549us/step - loss: 0.0644\n",
      "Epoch 7/25\n",
      "529/529 [==============================] - 0s 529us/step - loss: 0.0616\n",
      "Epoch 8/25\n",
      "529/529 [==============================] - 0s 526us/step - loss: 0.0615\n",
      "Epoch 9/25\n",
      "529/529 [==============================] - 0s 566us/step - loss: 0.0572\n",
      "Epoch 10/25\n",
      "529/529 [==============================] - 0s 540us/step - loss: 0.0627\n",
      "Epoch 11/25\n",
      "529/529 [==============================] - 0s 545us/step - loss: 0.0661\n",
      "Epoch 12/25\n",
      "529/529 [==============================] - 0s 549us/step - loss: 0.0564\n",
      "Epoch 13/25\n",
      "529/529 [==============================] - 0s 611us/step - loss: 0.0542\n",
      "Epoch 14/25\n",
      "529/529 [==============================] - 0s 585us/step - loss: 0.0513\n",
      "Epoch 15/25\n",
      "529/529 [==============================] - 0s 684us/step - loss: 0.0520\n",
      "Epoch 16/25\n",
      "529/529 [==============================] - 0s 700us/step - loss: 0.0494\n",
      "Epoch 17/25\n",
      "529/529 [==============================] - 0s 626us/step - loss: 0.0509\n",
      "Epoch 18/25\n",
      "529/529 [==============================] - 0s 576us/step - loss: 0.0433\n",
      "Epoch 19/25\n",
      "529/529 [==============================] - 0s 611us/step - loss: 0.0448\n",
      "Epoch 20/25\n",
      "529/529 [==============================] - 0s 551us/step - loss: 0.0416\n",
      "Epoch 21/25\n",
      "529/529 [==============================] - 0s 601us/step - loss: 0.0399\n",
      "Epoch 22/25\n",
      "529/529 [==============================] - 0s 568us/step - loss: 0.0417\n",
      "Epoch 23/25\n",
      "128/529 [======>.......................] - ETA: 0s - loss: 0.0374"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-df33a9290c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tarunm/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/tarunm/.local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tarunm/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tarunm/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tarunm/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "H = [2,3]\n",
    "C = [30,50,80]\n",
    "T = [20,50,75]\n",
    "n = 1\n",
    "for h in H:\n",
    "    for c in C:\n",
    "        e = 50\n",
    "        for t in T:\n",
    "            print\n",
    "            print '::::::::::::MODEL '+str(n)+' ::::::::::::::::'\n",
    "            print 'Number of Hidden Layers : '+str(h)\n",
    "            print 'Number of cells in Hidden Layers : '+str(c)\n",
    "            print 'Number of Time Steps : '+str(t)\n",
    "            print 'Number of Epochs : '+str(e)\n",
    "            print\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            X_test = []\n",
    "            y_test = []\n",
    "            for i in range(t, train_ts_scaled.shape[0]):\n",
    "                X_train.append(train_ts_scaled[i-t:i, :])\n",
    "                y_train.append(out_train_scaled[i, 0])\n",
    "            X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "            for i in range(t, test_ts_scaled.shape[0]):\n",
    "                X_test.append(test_ts_scaled[i-t:i, :])\n",
    "                y_test.append(out_test_scaled[i, 0])\n",
    "            X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "            model = Sequential()\n",
    "            for m in range(0,h):\n",
    "                model.add(SimpleRNN(units=c,return_sequences=True))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(units = 1))\n",
    "            model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "            model.fit(X_train, y_train, epochs = e, batch_size = 32)\n",
    "            err = model.evaluate(X_test, y_test)\n",
    "            print\n",
    "            print 'Model '+str(n)+' error : '+str(err)\n",
    "            print\n",
    "            print '================================================================='\n",
    "            e = e/2\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
